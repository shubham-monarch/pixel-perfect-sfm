{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70a5983c",
   "metadata": {},
   "source": [
    "In this notebook, we will build a 3D map of a scene from a small set of images and refine it with the featuremetric optimization. We then localize an image downloaded from the Internet and show the effect of the refinement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7c6f36",
   "metadata": {},
   "source": [
    "# Setup\n",
    "We start by defining some output paths: where the intermediate files will be stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379aa91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import tqdm, tqdm.notebook\n",
    "tqdm.tqdm = tqdm.notebook.tqdm  # notebook-friendly progress bars\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import numpy as np\n",
    "from hloc import extract_features, match_features, reconstruction, pairs_from_exhaustive, visualization\n",
    "from hloc.visualization import plot_images, read_image\n",
    "from hloc.utils.viz_3d import init_figure, plot_points, plot_reconstruction, plot_camera_colmap\n",
    "from pixsfm.util.visualize import init_image, plot_points2D\n",
    "from pixsfm.refine_hloc import PixSfM\n",
    "from pixsfm import ostream_redirect\n",
    "from PIL import Image, ImageDraw\n",
    "import pycolmap\n",
    "from pathlib import Path\n",
    "#import visualize_model\n",
    "# redirect the C++ outputs to notebook cells\n",
    "cpp_out = ostream_redirect(stderr=True, stdout=True)\n",
    "cpp_out.__enter__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b577c8a-72ac-48da-aac2-c4c2bd22c9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "print(torch.__version__)\n",
    "print(torch.cuda.get_arch_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3631a2",
   "metadata": {},
   "source": [
    "### Helper functions for relative pose calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0708a98e-2ea9-4808-bab6-a31983e21060",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "e_lw => left camera pose in world frame (4 * 4)\n",
    "e_rw => right camera pose in world frame (4 * 4)\n",
    "'''\n",
    "#def calculate_relative_pose(e_lw, e_rw):\n",
    "def calculate_relative_pose(e_lw: np.ndarray, e_rw: np.ndarray):\n",
    "    #print(f\"Inside the calculate_relative_pose function\")\n",
    "    from scipy.spatial.transform import Rotation\n",
    "    e_wl = np.linalg.inv(e_lw)\n",
    "    #print(f\"e_wl: {e_wl}\")\n",
    "    #e_rl = e_rw * np.linalg.inv(e_lw) #right camera in the frame of the left camera\n",
    "    #e_rl = e_rw * e_wl #right camera in the frame of the left camera\n",
    "    #print(f\"e_rl: {e_rl}\")\n",
    "    e_rl = np.dot(e_rw,np.linalg.inv(e_lw))\n",
    "    R = e_rl[:3,:3] #extracting the rotation matrix\n",
    "    dx = e_rl[0,3]\n",
    "    dy = e_rl[1,3]\n",
    "    dz = e_rl[2,3]\n",
    "    dquat = Rotation.from_matrix(R).as_quat()\n",
    "    #rel_pose =  [dx, dy] + dquat\n",
    "    rel_pose = [dx,dy,dz]\n",
    "    for q in dquat: \n",
    "        rel_pose.append(q)\n",
    "    return rel_pose\n",
    "    #return [dx,dy]\n",
    "    #print(f\"dx: {dx} dy: {dy} dquat: {dquat}\")\n",
    "\n",
    "\n",
    "def cam_extrinsics(img):\n",
    "    from read_write_model import qvec2rotmat\n",
    "    R = qvec2rotmat(img.qvec)\n",
    "    t = img.tvec.reshape(3,-1)\n",
    "    #print(f\"R: {R} t: {t}\")\n",
    "    R_t = np.concatenate((R,t), axis = 1)\n",
    "    #R_t = np.vstack([np.array([0,0,0,1]), R_t])\n",
    "    R_t = np.vstack([R_t, np.array([0,0,0,1])])\n",
    "    return R_t    #  4 * 4 matrix\n",
    "\n",
    "def calculate_relative_pose_between(left_idx: int, right_idx: int):\n",
    "    left_img = sparse_img_dict[left_idx]\n",
    "    right_img = sparse_img_dict[right_idx]\n",
    "    e_lw = cam_extrinsics(left_img)  #left camera pose w.r.t. world\n",
    "    e_rw = cam_extrinsics(right_img) #right camera pose w.r.t world\n",
    "    rel_pose = calculate_relative_pose(e_lw, e_rw)\n",
    "    return rel_pose\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77860966-409a-45fb-9df0-28f0a3794f69",
   "metadata": {},
   "source": [
    "### Camera positions WITHOUT Rig Bundle Adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16b074e-76b1-480c-af86-c4aa3ddefff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "sparse_dir = ref_dir_locked \n",
    "print(f\"sparse_dir: {sparse_dir.as_posix()}\")\n",
    "sparse_images = sparse_dir / \"images.bin\"\n",
    "sparse_points3D = sparse_dir / \"points3D.bin\"\n",
    "sparse_cameras = sparse_dir / \"cameras.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4122ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/skumar/colmap/scripts/python\")\n",
    "from read_write_model import read_images_binary \n",
    "sparse_img_dict = read_images_binary(sparse_images)\n",
    "print(f\"{len(sparse_img_dict.keys())} ==> {sparse_img_dict.keys()}\")\n",
    "print(f\"min_key: {min(sparse_img_dict.keys())} mx_key: {max(sparse_img_dict.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b633f78d-7fba-4d8d-8ab1-cd445552e066",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "rel_poses = []\n",
    "num_images = len(sparse_img_dict.keys())\n",
    "for idx in range(1, num_images // 2 + 1):\n",
    "    left_img = sparse_img_dict[idx]\n",
    "    right_img = sparse_img_dict[idx + 42]\n",
    "    #print(f\"left_img_name: {left_img.name} right_img_name: {right_img.name}\")\n",
    "    e_lw = cam_extrinsics(left_img)  #left camera pose w.r.t. world\n",
    "    e_rw = cam_extrinsics(right_img) #right camera pose w.r.t world\n",
    "    e_rl = calculate_relative_pose(e_lw, e_rw)\n",
    "    rel_poses.append(e_rl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd34d636-d470-4273-8c9c-258d08e313a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "df = pd.DataFrame(rel_poses, columns=['dx', 'dy', 'dz', 'qx' , 'qy', 'qz' , 'qw'])\n",
    "df.style"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3cc0fa-25ee-4136-942d-3a9422a15913",
   "metadata": {},
   "source": [
    "### Camera poses with Rig Bundle Adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0ceb78-de4c-4db3-bdfb-5cb8add43f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "rig_ba_sparse_dir = Path(os.path.expandvars('$HOME/rig_ba_model'))\n",
    "rig_ba_sparse_images = rig_ba_sparse_dir / \"images.bin\"\n",
    "rig_ba_sparse_points3D = rig_ba_sparse_dir / \"points3D.bin\"\n",
    "rig_ba_sparse_cameras = rig_ba_sparse_dir / \"cameras.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f269c61-bfc7-41f8-8dac-1148628ec948",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#sys.path.append(\"/home/skumar/colmap/scripts/python\")\n",
    "sys.path.append(os.path.expandvars('$HOME/colmap/scripts/python'))\n",
    "from read_write_model import read_images_binary \n",
    "rig_ba_sparse_img_dict = read_images_binary(rig_ba_sparse_images)\n",
    "print(f\"{len(rig_ba_sparse_img_dict.keys())} => {rig_ba_sparse_img_dict.keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f38e7a-2547-4b16-b6a2-a25dee4b71e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "rig_ba_rel_poses = []\n",
    "num_images = len(rig_ba_sparse_img_dict.keys())\n",
    "for idx in range(1, num_images // 2 + 1):\n",
    "    left_img = rig_ba_sparse_img_dict[idx]\n",
    "    right_img = rig_ba_sparse_img_dict[idx + 42]\n",
    "    if idx < 5:\n",
    "        print(f\"left_img_name: {left_img.name} right_img_name: {right_img.name}\")\n",
    "    e_lw = cam_extrinsics(left_img)  #left camera pose w.r.t. world\n",
    "    e_rw = cam_extrinsics(right_img) #right camera pose w.r.t world\n",
    "    rel_pose = calculate_relative_pose(e_lw, e_rw)\n",
    "    rig_ba_rel_poses.append(rel_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45309f8b-af8f-417b-b928-a44ab79c30c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "df = pd.DataFrame(rig_ba_rel_poses, columns=['dx', 'dy', 'dz', 'qx' , 'qy', 'qz' , 'qw'])\n",
    "df.style"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
