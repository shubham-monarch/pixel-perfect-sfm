{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70a5983c",
   "metadata": {},
   "source": [
    "In this notebook, we will build a 3D map of a scene from a small set of images and refine it with the featuremetric optimization. We then localize an image downloaded from the Internet and show the effect of the refinement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7c6f36",
   "metadata": {},
   "source": [
    "# Setup\n",
    "We start by defining some output paths: where the intermediate files will be stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379aa91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import tqdm, tqdm.notebook\n",
    "tqdm.tqdm = tqdm.notebook.tqdm  # notebook-friendly progress bars\n",
    "from pathlib import Path\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "from hloc import extract_features, match_features, reconstruction, pairs_from_exhaustive, visualization\n",
    "from hloc.visualization import plot_images, read_image\n",
    "from hloc.utils.viz_3d import init_figure, plot_points, plot_reconstruction, plot_camera_colmap\n",
    "\n",
    "from pixsfm.util.visualize import init_image, plot_points2D\n",
    "from pixsfm.refine_hloc import PixSfM\n",
    "from pixsfm import ostream_redirect\n",
    "from PIL import Image, ImageDraw\n",
    "import pycolmap\n",
    "#import visualize_model\n",
    "# redirect the C++ outputs to notebook cells\n",
    "cpp_out = ostream_redirect(stderr=True, stdout=True)\n",
    "cpp_out.__enter__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b577c8a-72ac-48da-aac2-c4c2bd22c9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "print(torch.__version__)\n",
    "print(torch.cuda.get_arch_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab294072",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = Path('datasets/monarch/')\n",
    "outputs = Path('outputs/monarch-demo/')\n",
    "!rm -rf $outputs\n",
    "sfm_pairs = outputs / 'pairs-sfm.txt'\n",
    "loc_pairs = outputs / 'pairs-loc.txt'\n",
    "features = outputs / 'features.h5'\n",
    "matches = outputs / 'matches.h5'\n",
    "raw_dir = outputs / \"raw\"\n",
    "ref_dir = outputs / \"ref\"\n",
    "''' model location in case of intrinsics locked '''\n",
    "ref_dir_locked = outputs / \"ref_locked\"\n",
    "''' model location in case of intrinsics not locked '''\n",
    "ref_dir_not_locked = outputs / \"ref_dir_not_locked\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bef9e3",
   "metadata": {},
   "source": [
    "Here we will use SuperPoint local features with the SuperGlue matcher, but it's easy to switch to other features like SIFT or R2D2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4182c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_conf = extract_features.confs['superpoint_aachen']\n",
    "matcher_conf = match_features.confs['superglue']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29335da0",
   "metadata": {},
   "source": [
    "# 3D mapping and refinement\n",
    "First we list the images used for mapping. These are all day-time shots of Sacre Coeur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31de7d45-8e7a-48b3-a848-b76bbad407da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''masking of the tractor hood from the images '''\n",
    "# ''' output => datasets/monarch/{target_folder}/image_name.jpg '''\n",
    "# def draw_box_around_tractor_hood(image_path, target_folder): \n",
    "#     image = Image.open(image_path)\n",
    "#     w, h = image.size\n",
    "#     box_x1, box_y1 = 460, 770  # Top-left corner\n",
    "#     box_x2, box_y2 = 1630, 1080  # Bottom-right corner\n",
    "#     outline_color = (0, 0, 0)  # Red in RGB format\n",
    "#     fill_color = (0, 0, 0)  # Black in RGB format\n",
    "#     draw = ImageDraw.Draw(image)\n",
    "#     draw.rectangle([box_x1, box_y1, box_x2, box_y2], outline=outline_color, fill=fill_color)\n",
    "#     directory_path,filename = os.path.split(image_path)\n",
    "#     parent_directory_path = os.path.dirname(directory_path)\n",
    "#     target_directory = os.path.join(parent_directory_path, target_folder)\n",
    "#     os.makedirs(target_directory, exist_ok = True)\n",
    "#     target_image_path = os.path.join(target_directory,filename)\n",
    "#     image.save(target_image_path)\n",
    "#     return target_image_path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fe8e94-ca6f-4420-8e62-87a7670f9f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "references_left = [str(p.relative_to(images)) for i, p in enumerate((images / 'left/').iterdir())]\n",
    "references_right = [str(p.relative_to(images)) for i, p in enumerate((images / 'right/').iterdir())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3aa6864-1d3e-47b7-992b-6797cc6faf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(references_left))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5d23a0-b8f2-4fe7-b607-f46baca391e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "references_left = sorted(references_left, key=lambda x: int(x.split('/')[-1].split('.')[0]))\n",
    "references_right = sorted(references_right, key=lambda x: int(x.split('/')[-1].split('.')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8915af4-57e6-4eef-bd6c-e773171e2d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(references_left))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a11524d-31b8-4cec-9092-2de82fd1d392",
   "metadata": {},
   "outputs": [],
   "source": [
    "references_left = references_left[40:82] \n",
    "references_right = references_right[40:82]\n",
    "references = references_left + references_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362270f3-a77e-47f6-adec-7e1b1a0c8a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''sorting references so that each stereo pair is together in the list '''\n",
    "references = sorted(references, key=lambda x: int(x.split('/')[-1].split('.')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7620aa-6fe9-4366-8f4e-8a7e15891aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a2b029-23b7-44a0-9f7c-20dd5d7e5f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ''' masking the tractor hood in all the images'''\n",
    "# ''' returns list of path to the masked images '''\n",
    "# start_time = time.time()\n",
    "# target_folder = \"masked_images\"\n",
    "# masked_references = [draw_box_around_tractor_hood(p, target_folder) for p in references]\n",
    "# end_time = time.time()\n",
    "# elapsed_time = end_time - start_time\n",
    "\n",
    "# target_path = os.path.join(images, target_folder)\n",
    "\n",
    "# ''' sorting masked_references sequentially '''\n",
    "# ''' smf => sorted masked references '''\n",
    "# #smf = sorted(masked_references, key = lambda x: int(((x.split(\"/\")[-1]).split(\".\")[0]).split(\"_\")[0]))\n",
    "\n",
    "# print(f\"type(masked_references): {type(masked_references)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2837d405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# smf = []\n",
    "# for i in range(0, len(references)//2 - 1): \n",
    "#     left  = \"masked_images/\" + str(i) + \"_left.jpg\"\n",
    "#     right = \"masked_images/\" + str(i) + \"_right.jpg\"\n",
    "#     smf.append(left)\n",
    "#     smf.append(right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922b5f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"smf: {smf}\")\n",
    "# print(f\"len(smf) : {len(smf)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4e1654-5661-4ae3-9de4-4254257c6cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed8d631-c4da-4ac0-b469-507c13528f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "references[59]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34abc54c-1024-4608-b0ed-7c35951c3c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_path_ = extract_features.main(feature_conf, images, image_list= references, feature_path=features)\n",
    "#match_features.main(matcher_conf, sfm_pairs, features=features, matches=matches);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a937f7d9-92c6-4a75-aaec-a3e4af511715",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hloc.extract_features import list_h5_names\n",
    "h5_feature_names = list_h5_names(features_path_)\n",
    "print(f\"len(h5_feature_names): {len(h5_feature_names)}\")\n",
    "print(h5_feature_names[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e86f9d",
   "metadata": {},
   "source": [
    "Then we extract features and match them across image pairs. Since we deal with few images, we simply match all pairs exhaustively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21540f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_path_ = extract_features.main(feature_conf, images, image_list=references_final, feature_path=features)\n",
    "# #match_features.main(matcher_conf, sfm_pairs, features=features, matches=matches);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9158e3-dad2-4197-bc21-e84e273b52c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hloc.utils.viz import plot_keypoints, save_plot\n",
    "from hloc.utils.io import get_keypoints\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "ref_trim_ = references[:4]\n",
    "plot_images([read_image(images / r) for r in ref_trim_], dpi=50, figsize=4.2)\n",
    "\n",
    "kps_list_ = [] \n",
    "for r in ref_trim_:\n",
    "    kps = get_keypoints(features_path_, r)\n",
    "    print(type(kps))\n",
    "    kps_list_.append(kps)\n",
    "    \n",
    "plot_keypoints(kps_list_, colors = \"red\",  ps = 10)\n",
    "\n",
    "current_path_ = os.getcwd()\n",
    "\n",
    "print(\"current_path: \", current_path_)\n",
    "\n",
    "print(type(current_path_))\n",
    "\n",
    "final_path = current_path_ + \"/kps.png\"\n",
    "\n",
    "\n",
    "save_plot(final_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7609a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections.abc as collections\n",
    "isinstance(references, collections.Iterable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08ee806-24b4-43ca-a2fc-814f1677a297",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_from_exhaustive.stereo_main(sfm_pairs, image_list=references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d90198-7012-4d2a-9158-841c889e3b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"features: \", features)\n",
    "#print(\"matches: \", matches)\n",
    "match_features.main(matcher_conf, sfm_pairs, features=features, matches=matches);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2a6c6c-abe3-4727-bbaf-fc46475aadf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(list_h5_names(matches)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e5fd25-9f5a-4aa4-b5d5-606f03b93757",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list_h5_names(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932d33a9-0aca-465d-bef1-6a233768a697",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_names = list_h5_names(matches)\n",
    "for name in match_names: \n",
    "    if \"right-52.jpg\" in name: \n",
    "        print (name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b08e42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' script to plot matches between two frames'''\n",
    "from hloc.utils.viz import plot_matches\n",
    "from hloc.utils.io import get_matches, get_keypoints\n",
    "#img1 = images.joinpath(references[0])\n",
    "#img2 = images.joinpath(references[1])\n",
    "\n",
    "#print(f\"img1 : {img1.as_posix()} img_2: {img2.as_posix()}\")\n",
    "\n",
    "print(f\"features: {features}\")\n",
    "kp1 = get_keypoints(features, references[0])\n",
    "kp2 = get_keypoints(features, references[1])\n",
    "print(f\"kp1.shape: {kp1.shape}\")\n",
    "\n",
    "m, _ = get_matches(matches, references[0], references[1])\n",
    "print(f\"m.shape: {m.shape}\")\n",
    "\n",
    "m1 = np.array([kp1[i] for i in m[:,0]])\n",
    "m2 = np.array([kp2[i] for i in m[:, 1]])\n",
    "\n",
    "#print(m1[:10])\n",
    "\n",
    "plot_images([read_image(images / r) for r in references[:2]], dpi=50, figsize=4.2)\n",
    "#plot_matches(kp1.transpose, kp2.transpose)\n",
    "#plot_matches(kp1.transpose, kp2.transpose)\n",
    "plot_matches(m1, m2)\n",
    "#plot_matches(m[:,0], m[:,1])\n",
    "#print(m[:10])\n",
    "#kp1 = \n",
    "#matches, scores = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e232823a",
   "metadata": {},
   "source": [
    "Now we run the reconstruction with and without the featuremetric refinement. For this dataset, when computing the dense features, we resize the images such that they are not larger than 1024 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534ef73b-b4dc-49cb-be9a-d4d104ec13f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fx = 1093.2768\n",
    "fy = 1093.2768\n",
    "cx = 964.989\n",
    "cy = 569.276\n",
    "opencv_camera_params =','.join(map(str, (fx, fy, cx, cy, 0, 0, 0, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc0a949-5ff9-4053-ac91-0446a8c8ca00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sfm = PixSfM({\"dense_features\": {\"max_edge\": 1024}})\n",
    "\n",
    "\n",
    "#conf1 = {\"dense_features\": {\"max_edge\": 1024}}\n",
    "\n",
    "conf2 = {\n",
    "    \"BA\": {\"optimizer\": {\"refine_focal_length\": False,\"refine_extra_params\": False, \"refine_extrinsics\": False}},\n",
    "    \"dense_features\": {\"max_edge\":1024}\n",
    "}\n",
    "\n",
    "sfm = PixSfM(conf=conf2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5197d7df-5fe0-4b08-98de-b8dc7d832b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''CASE 1 => INITIAL K IS PROVIDED + K IS NOT LOCKED '''\n",
    "'''\n",
    "image_options = dict(camera_model='OPENCV', \n",
    "                    camera_params=opencv_camera_params,\n",
    "                    )\n",
    "mapper_options_locked = dict(ba_refine_focal_length=False, \n",
    "                      ba_refine_extra_params=False,\n",
    "                     ba_refine_principal_point=False)\n",
    "\n",
    "hloc_args_locked = dict(image_list=references,\n",
    "                image_options=image_options,\n",
    "                # mapper_options=mapper_options_locked,\n",
    "                camera_mode=\"PER_FOLDER\")\n",
    "\n",
    "K_locked, sfm_outputs_locked = sfm.reconstruction(ref_dir_not_locked, images, sfm_pairs, features, matches, **hloc_args_locked)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f58135-114b-47c8-9570-eeb4367e9924",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''CASE 2 => INITIAL K IS PROVIDED + K IS LOCKED '''\n",
    "\n",
    "image_options = dict(camera_model='OPENCV', \n",
    "                     camera_params=opencv_camera_params\n",
    "                    )\n",
    "\n",
    "mapper_options_one = dict(ba_refine_focal_length=False, \n",
    "                      ba_refine_extra_params=False,\n",
    "                     ba_refine_principal_point=False)\n",
    "\n",
    "mapper_options_two = dict(ba_refine_focal_length=False, \n",
    "                      ba_refine_extra_params=False,\n",
    "                     ba_refine_principal_point=False)\n",
    "\n",
    "hloc_args_not_locked = dict(image_list=references,\n",
    "                image_options=image_options,\n",
    "                camera_mode=\"PER_FOLDER\",\n",
    "                mapper_options=mapper_options_two)\n",
    "\n",
    "#hloc_args_not_locked = dict(image_list=references)\n",
    "\n",
    "K_locked, sfm_outputs_not_locked = sfm.reconstruction(ref_dir_locked, images, sfm_pairs, features, matches, **hloc_args_not_locked)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0708a98e-2ea9-4808-bab6-a31983e21060",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "e_lw => left camera pose in world frame (4 * 4)\n",
    "e_rw => right camera pose in world frame (4 * 4)\n",
    "'''\n",
    "#def calculate_relative_pose(e_lw, e_rw):\n",
    "def calculate_relative_pose(e_lw: np.ndarray, e_rw: np.ndarray):\n",
    "    #print(f\"Inside the calculate_relative_pose function\")\n",
    "    from scipy.spatial.transform import Rotation\n",
    "    e_wl = np.linalg.inv(e_lw)\n",
    "    #print(f\"e_wl: {e_wl}\")\n",
    "    #e_rl = e_rw * np.linalg.inv(e_lw) #right camera in the frame of the left camera\n",
    "    #e_rl = e_rw * e_wl #right camera in the frame of the left camera\n",
    "    #print(f\"e_rl: {e_rl}\")\n",
    "    e_rl = np.dot(e_rw,np.linalg.inv(e_lw))\n",
    "    R = e_rl[:3,:3] #extracting the rotation matrix\n",
    "    dx = e_rl[0,3]\n",
    "    dy = e_rl[1,3]\n",
    "    dz = e_rl[2,3]\n",
    "    dquat = Rotation.from_matrix(R).as_quat()\n",
    "    #rel_pose =  [dx, dy] + dquat\n",
    "    rel_pose = [dx,dy,dz]\n",
    "    for q in dquat: \n",
    "        rel_pose.append(q)\n",
    "    return rel_pose\n",
    "    #return [dx,dy]\n",
    "    #print(f\"dx: {dx} dy: {dy} dquat: {dquat}\")\n",
    "\n",
    "\n",
    "def cam_extrinsics(img):\n",
    "    from read_write_model import qvec2rotmat\n",
    "    R = qvec2rotmat(img.qvec)\n",
    "    t = img.tvec.reshape(3,-1)\n",
    "    #print(f\"R: {R} t: {t}\")\n",
    "    R_t = np.concatenate((R,t), axis = 1)\n",
    "    #R_t = np.vstack([np.array([0,0,0,1]), R_t])\n",
    "    R_t = np.vstack([R_t, np.array([0,0,0,1])])\n",
    "    return R_t    #  4 * 4 matrix\n",
    "\n",
    "def calculate_relative_pose_between(left_idx: int, right_idx: int):\n",
    "    left_img = sparse_img_dict[left_idx]\n",
    "    right_img = sparse_img_dict[right_idx]\n",
    "    e_lw = cam_extrinsics(left_img)  #left camera pose w.r.t. world\n",
    "    e_rw = cam_extrinsics(right_img) #right camera pose w.r.t world\n",
    "    rel_pose = calculate_relative_pose(e_lw, e_rw)\n",
    "    return rel_pose\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4a0dba-6fd1-49bc-a049-00ea02a5f4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from read_write_model import qvec2rotmat\n",
    "qvec = [1,0,0,0]\n",
    "R = qvec2rotmat(qvec)\n",
    "print(f\"R: {R}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77860966-409a-45fb-9df0-28f0a3794f69",
   "metadata": {},
   "source": [
    "#### Camera positions WITHOUT Rig Bundle Adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16b074e-76b1-480c-af86-c4aa3ddefff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "#sparse_dir = Path(\"/home/skumar/stereo_colmap_cli_output/sparse/\")\n",
    "#sparse_dir = ref_dir_locked / \"hloc\"\n",
    "sparse_dir = Path(\"/home/skumar/stereo_colmap_cli_output/\")\n",
    "print(f\"sparse_dir: {sparse_dir.as_posix()}\")\n",
    "sparse_images = sparse_dir / \"images.bin\"\n",
    "sparse_points3D = sparse_dir / \"points3D.bin\"\n",
    "sparse_cameras = sparse_dir / \"cameras.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1ff935-5e51-4f96-8502-851a5b3ad467",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/skumar/colmap/scripts/python\")\n",
    "from read_write_model import read_images_binary \n",
    "sparse_img_dict = read_images_binary(sparse_images)\n",
    "print(f\"{len(sparse_img_dict.keys())} ==> {sparse_img_dict.keys()}\")\n",
    "print(f\"min_key: {min(sparse_img_dict.keys())} mx_key: {max(sparse_img_dict.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9239668-3246-4c31-b5de-3cc014afe1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_extrinsics(sparse_img_dict[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b633f78d-7fba-4d8d-8ab1-cd445552e066",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "rel_poses = []\n",
    "num_images = len(sparse_img_dict.keys())\n",
    "for idx in range(1, num_images // 2 + 1):\n",
    "    left_img = sparse_img_dict[idx]\n",
    "    right_img = sparse_img_dict[idx + 42]\n",
    "    #print(f\"left_img_name: {left_img.name} right_img_name: {right_img.name}\")\n",
    "    e_lw = cam_extrinsics(left_img)  #left camera pose w.r.t. world\n",
    "    e_rw = cam_extrinsics(right_img) #right camera pose w.r.t world\n",
    "    e_rl = calculate_relative_pose(e_lw, e_rw)\n",
    "    rel_poses.append(e_rl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd34d636-d470-4273-8c9c-258d08e313a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "df = pd.DataFrame(rel_poses, columns=['dx', 'dy', 'dz', 'qx' , 'qy', 'qz' , 'qw'])\n",
    "df.style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e088c5d9-f2be-4e8c-92e8-15390d6dd25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dr = np.hstack((np.array(df['dx']).reshape(-1,1), np.array(df['dy']).reshape(-1,1), np.array(df['dz']).reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238e9592-006f-4933-8ad6-4373b396b8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13c85e6-6e0e-44ee-9793-3f1dfd56a319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = np.linalg.norm(dr, axis=1, ord=2)\n",
    "# plt.hist(x, 100)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3cc0fa-25ee-4136-942d-3a9422a15913",
   "metadata": {},
   "source": [
    "#### Camera poses with Rig Bundle Adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0ceb78-de4c-4db3-bdfb-5cb8add43f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "rig_ba_sparse_dir = Path(\"/home/skumar/rig_dense/sparse/\")\n",
    "print(f\"rig_ba_sparse_dir: {rig_ba_sparse_dir.as_posix()}\")\n",
    "rig_ba_sparse_images = rig_ba_sparse_dir / \"images.bin\"\n",
    "rig_ba_sparse_points3D = rig_ba_sparse_dir / \"points3D.bin\"\n",
    "rig_ba_sparse_cameras = rig_ba_sparse_dir / \"cameras.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f269c61-bfc7-41f8-8dac-1148628ec948",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/skumar/colmap/scripts/python\")\n",
    "from read_write_model import read_images_binary \n",
    "rig_ba_sparse_img_dict = read_images_binary(rig_ba_sparse_images)\n",
    "print(f\"{len(rig_ba_sparse_img_dict.keys())} => {rig_ba_sparse_img_dict.keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f38e7a-2547-4b16-b6a2-a25dee4b71e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "rig_ba_rel_poses = []\n",
    "num_images = len(rig_ba_sparse_img_dict.keys())\n",
    "for idx in range(1, num_images // 2 + 1):\n",
    "    left_img = rig_ba_sparse_img_dict[idx]\n",
    "    right_img = rig_ba_sparse_img_dict[idx + 42]\n",
    "    if idx < 5:\n",
    "        print(f\"left_img_name: {left_img.name} right_img_name: {right_img.name}\")\n",
    "    e_lw = cam_extrinsics(left_img)  #left camera pose w.r.t. world\n",
    "    e_rw = cam_extrinsics(right_img) #right camera pose w.r.t world\n",
    "    rel_pose = calculate_relative_pose(e_lw, e_rw)\n",
    "    rig_ba_rel_poses.append(rel_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45309f8b-af8f-417b-b928-a44ab79c30c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "df = pd.DataFrame(rig_ba_rel_poses, columns=['dx', 'dy', 'dz', 'qx' , 'qy', 'qz' , 'qw'])\n",
    "df.style"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09ef122",
   "metadata": {},
   "source": [
    "We now plot the reconstructions side-by-side. We can click on the legend entries to toggle them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a453691a-8804-4a2d-a1a1-5a43ed8b102c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#curr_directory = os.getcwd()\n",
    "#dense_model = Path(\"outputs/mvs/\")\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pycolmap\n",
    "#ply_path = Path(\"/home/skumar/colmap_output/fused.ply\")\n",
    "#bin_path_1 = Path(\"/home/skumar/pixel-perfect-sfm/outputs/monarch-demo/ref_dir_not_locked/hloc/\")\n",
    "#bin_path_2 = Path(\"/home/skumar/pixel-perfect-sfm/outputs/monarch-demo/ref_dir_not_locked/\")\n",
    "\n",
    "#bin_path = Path(\"/home/skumar/colmap_cli_output/\")\n",
    "locked_path = Path(\"/home/skumar/colmap_cli_output/\")\n",
    "#not_locked_path = ref_dir_locked\n",
    "#ply_model = pycolmap.Reconstruction()\n",
    "#ply_model.import_PLY(ply_path.as_posix())\n",
    "\n",
    "#bin_model1 = pycolmap.Reconstruction()\n",
    "#bin_model1.read_binary(bin_path_1.as_posix())\n",
    "\n",
    "#bin_model2 = pycolmap.Reconstruction()\n",
    "#bin_model2.read_binary(bin_path_2.as_posix())\n",
    "\n",
    "#bin_model = pycolmap.Reconstruction()\n",
    "#bin_model.read_binary(bin_path.as_posix())\n",
    "\n",
    "locked_model = pycolmap.Reconstruction()\n",
    "locked_model.read_binary(locked_path.as_posix())\n",
    "\n",
    "#not_locked_model = pycolmap.Reconstruction()\n",
    "#not_locked_model.read_binary(not_locked_path.as_posix())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd33915b-76f0-465d-9aa6-5c136b47df99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f\"ply_model.summary(): {ply_model.summary()}\")\n",
    "#print(f\"bin_model.summary(): {bin_model.summary()}\")\n",
    "\n",
    "print(f\"locked_model.summary(): {locked_model.summary()}\")\n",
    "#print(f\"not_locked_model.summary(): {not_locked_model.summary()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5ed738-9132-4fd6-b712-199c35c14b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig3d = init_figure()\n",
    "args = dict(max_reproj_error=3.0, min_track_length=2, cs=1.2)\n",
    "#plot_reconstruction(fig3d, locked_model, color='rgba(255, 0, 0, 0.5)', name=\"K_not_locked\", **args)\n",
    "#plot_reconstruction(fig3d, K_locked, color='rgba(0, 255, 0, 0.5)', name=\"K_locked\", **args)\n",
    "plot_reconstruction(fig3d, locked_model, color='rgba(255, 255, 0, 0.5)', name=\"K_\", **args)\n",
    "#plot_reconstruction(fig3d, locked_model, color='rgba(255,0,0,0.5)', name=\"locked_model\")\n",
    "\n",
    "fig3d.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1677d4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(1, \"/home/skumar/colmap/scripts/python/\")\n",
    "points  = read_write_model.read_points3D_binary(Path(\"/home/skumar/colmap_cli_output/points3D.bin\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83bda90",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"type(points): {type(points)}\")\n",
    "#print(f\"list(point.keys(): {list(points.keys()}))\n",
    "key_list = list(points.keys())\n",
    "print(f\"key_list[0:10] : {key_list[0:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca5cdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(points[155652])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcc058f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(1, \"/home/skumar/colmap/scripts/python/\")\n",
    "import read_write_fused_vis\n",
    "vis_model = read_write_fused_vis.read_fused(\"/home/skumar/colmap_cli_output/fused.ply\", \"/home/skumar/colmap_cli_output/fused.ply.vis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ff3c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"type(vis_model) : {type(vis_model)}\")\n",
    "print(f\"len(vis_model) : {len(vis_model)}\")\n",
    "vis_model[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bdf7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f\"bin_model1.summary(): {bin_model1.summary()}\")\n",
    "#print(f\"bin_model1.summary(): {bin_model1.summary()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901ccad4-1bc0-4020-aa62-aba0630f39e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/skumar/colmap/scripts/python\")\n",
    "import read_write_fused_vis\n",
    "f1 = Path(\"/home/skumar/colmap_cli_output/fused.ply\")\n",
    "f2 = Path(\"/home/skumar/colmap_cli_output/fused.ply.vis\")\n",
    "#os.path.exists(f1)\n",
    "#os.path.exists(f2)\n",
    "#df = read_write_fused_vis.read_fused(f1,f2)\n",
    "df = read_write_fused_vis.read_fused(f1.as_posix(),f2.as_posix())\n",
    "#@r@ead_write_fused_vis.read_fused(f1.as_posix(), f2.as_posix())\n",
    "print(df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c6571f-d369-4be3-bf4e-1d9bbaacfd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from read_write_model import read_images_binary\n",
    "p1 = Path(\"/home/skumar/colmap_cli_output/images.bin\")\n",
    "os.path.exists(p1)\n",
    "p2 = Path(\"/home/skumar/colmap_cli_output/sparse/images.bin\")\n",
    "os.path.exists(p2)\n",
    "d1 = read_images_binary(p1.as_posix())\n",
    "d2 = read_images_binary(p2.as_posix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6af43a-c756-4049-b465-cbcac25acb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"type(d1): {type(d1)}\")\n",
    "print(f\"d1.keys(): {d1.keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8947bd04-5edf-463c-84e0-b20a24756251",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(df))\n",
    "print(df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a0b059-ac4a-4972-9412-06d9e749612d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(K_not_locked.summary())\n",
    "print(dense_reconstruction.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a2c3df-5c46-4a93-8293-1e6d805efdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig3d = init_figure()\n",
    "args = dict(max_reproj_error=30.0, min_track_length=2, cs=1.2)\n",
    "#plot_reconstruction(fig3d, K_locked, color='rgba(255, 0, 0, 0.5)', name=\"K_locked\", **args)\n",
    "plot_reconstruction(fig3d, bin_model, color='rgba(0, 255, 0, 0.5)', name=\"K_not_locked\", **args)\n",
    "\n",
    "fig3d.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe182bbf-0d10-4d1b-bf2c-8acd1e714f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_reconstruction.export_PLY(\"dense_reconstruction.ply\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cac2f0-bcfe-402b-9945-04e917581273",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_reproj_error = 3.0\n",
    "min_track_length=2\n",
    "rec = dense_reconstruction\n",
    "p3Ds = [p3D for _, p3D in rec.points3D.items()]\n",
    "    \n",
    "xyzs = [p3D.xyz for p3D in p3Ds]\n",
    "print(xyzs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56439fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig3d = init_figure()\n",
    "args = dict(max_reproj_error=3.0, min_track_length=2, cs=1)\n",
    "#plot_reconstruction(fig3d, K_locked_dense, color='rgba(0, 255, 0, 0.5)', name=\"K_locked\", **args)\n",
    "plot_reconstruction(fig3d, x, color='rgba(255, 255, 0, 0.5)', name=\"K_not_locked\", **args)\n",
    "\n",
    "fig3d.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91e901d-e019-4539-8565-692521e4031e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig3d = init_figure()\n",
    "args = dict(max_reproj_error=30.0, min_track_length=2, cs=1)\n",
    "plot_reconstruction(fig3d, K_locked_dense, color='rgba(0, 255, 0, 0.5)', name=\"K_locked\", **args)\n",
    "#plot_reconstruction(fig3d, K_not_locked, color='rgba(255, 255, 0, 0.5)', name=\"K_not_locked\", **args)\n",
    "\n",
    "fig3d.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851f6aa9",
   "metadata": {},
   "source": [
    "We can also visualize the detected keypoints (blue) and the final reprojections (red) for a given mapping image. You can drag to zoom in. As you can see, the points were refined by a few pixels at most but the 3D points and camera poses can be refined up to a few meters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc46954",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = refined.images[refined.reg_image_ids()[0]]\n",
    "cam = refined.cameras[img.camera_id]\n",
    "fig = init_image(images / img.name)    \n",
    "plot_points2D(fig, [p2D.xy for p2D in img.points2D if p2D.has_point3D()])\n",
    "plot_points2D(fig, cam.world_to_image(img.project(refined)), color='rgba(255, 0, 0, 0.5)')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b475523",
   "metadata": {},
   "source": [
    "## PointCloud Segmentation\n",
    "Segementation of the dense pointcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0074a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/skumar/colmap/scripts/python\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc286cf",
   "metadata": {},
   "source": [
    "### Analysing Sparse Pointcloud Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4768fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_dir = Path(\"/home/skumar/bkp/stereo_colmap_cli_output/sparse/\")\n",
    "print(f\"sparse_dir: {sparse_dir.as_posix()}\")\n",
    "sparse_images = sparse_dir / \"images.bin\"\n",
    "sparse_points3D = sparse_dir / \"points3D.bin\"\n",
    "sparse_cameras = sparse_dir / \"cameras.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7293679",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_model = pycolmap.Reconstruction()\n",
    "sparse_model.read_binary(sparse_dir.as_posix())\n",
    "print(f\"sparse_model.summary(): {sparse_model.summary()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6817fac-5219-4f54-acbc-c88544ce325e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_model.export_PLY(\"sparse_model.ply\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7028686",
   "metadata": {},
   "source": [
    "### Loading Dense PointCloud BIN Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05502cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_dir = Path(\"/home/skumar/rig_stereo_colmap_cli_output/\")\n",
    "dense_images = dense_dir / \"images.bin\"\n",
    "dense_points3D = dense_dir / \"points3D.bin\"\n",
    "dense_cameras = dense_dir / \"cameras.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52cbf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_colmap = pycolmap.Reconstruction()\n",
    "dense_colmap.read_binary(dense_dir.as_posix())\n",
    "print(f\"summary: {dense_colmap.summary()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ef1f20-c3f3-40fc-aa42-88560a2e02b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_colmap.export_PLY(\"rig_sparse.ply\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6bed04",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig3d = init_figure()\n",
    "args = dict(max_reproj_error=3.0, min_track_length=2, cs=20)\n",
    "#plot_reconstruction(fig3d, dense_colmap, color='rgba(255, 255, 0, 0.5)', name=\"dense_colmap\", **args)\n",
    "plot_reconstruction(fig3d, dense_colmap, color='rgba(255, 255, 0, 0.5)', name=\"dense_colmap\", **args)\n",
    "fig3d.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c810e48",
   "metadata": {},
   "source": [
    "### Analysing Dense PointCloud BIN Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec977c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Analysing images.bin'''\n",
    "from read_write_model import read_images_binary\n",
    "a = read_images_binary(dense_images)\n",
    "#a = read_write_model.read_images_binary(dense_images)\n",
    "print(type(a))\n",
    "#print(f\"min_key: {min(a.keys())} mx_key: {max(a.keys())}\")\n",
    "#print(a[1])\n",
    "#print(a[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab41364",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Analysing sparse/images.bin'''\n",
    "from read_write_model import read_images_binary\n",
    "a = read_images_binary(sparse_images)\n",
    "#a = read_write_model.read_images_binary(dense_images)\n",
    "print(type(a))\n",
    "#print(f\"min_key: {min(a.keys())} mx_key: {max(a.keys())}\")\n",
    "#print(a[1])\n",
    "#print(a[1])\n",
    "print(a.keys())\n",
    "print(type(a[29]))\n",
    "print(a[29])\n",
    "print(f\"dir(a[29]): {dir(a[29])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9e54b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"dir(dense_colmap): {dir(dense_colmap)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914fc67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"dir(dense_colmap.images: {dir(dense_colmap.images)}\")\n",
    "#print(f\"dir(dense_colmap.images: {dir(dense_colmap.images.items)}\")\n",
    "#print(f\"dir(dense_colmap.images: {dir(dense_colmap.images.keys)}\")\n",
    "#print(f\"dir(dense_colmap.images: {dir(dense_colmap.images.values)}\")\n",
    "\n",
    "print(f\"type(dense_colmap.images: {type(dense_colmap.images)}\")\n",
    "#print(f\"type(dense_colmap.images.items: {type(dense_colmap.images.items)}\")\n",
    "#print(f\"type(dense_colmap.images.keys: {type(dense_colmap.images.keys)}\")\n",
    "#print(f\"type(dense_colmap.images.values: {type(dense_colmap.images.values)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6433916",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in dense_colmap.images.items():\n",
    "    print(f\"Key: {key}, Value: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d931f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_list = dense_colmap.images.keys()\n",
    "print(f\"len(key_list): {len(key_list)} type(key_list): {type(key_list)}\")\n",
    "#print(key_list[:10])\n",
    "for k in key_list: \n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f2eb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in a.items():\n",
    "    print(f\"key: {key} a[key].id: {a[key].id} a[key].name: {a[key].name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d81f92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Analysing cameras.bin'''\n",
    "from read_write_model import read_cameras_binary\n",
    "b = read_cameras_binary(dense_cameras)\n",
    "print(f\"b.keys(): {list(b.keys())}\")\n",
    "for k, v in b.items():\n",
    "    v_dict  = v._asdict()\n",
    "    for kk, vv in v_dict.items():\n",
    "        print(f\"{kk}:{vv}\")\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2a458a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from read_write_model import read_points3D_binary\n",
    "points3D_bin = read_points3D_binary(dense_points3D)\n",
    "print(type(c))\n",
    "print(f\"mn: {min(c.keys())} mx: {max(c.keys())}\")\n",
    "print(f\"type(c[6904] : {type(c[6904])}\")\n",
    "for k, v in c[6904]._asdict().items():\n",
    "    print(f\"{k}: {v}\")\n",
    "\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f6125a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_model = pycolmap.Reconstruction()\n",
    "dense_model.read_binary(dense_dir.as_posix())\n",
    "\n",
    "print(f\"dense_model.summary(): {dense_model.summary()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43ac712",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "print((dense_model.num_reg_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc52192",
   "metadata": {},
   "source": [
    "### Loading Dense PointCloud PLY Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab15d17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/home/skumar/colmap/scripts/python/\")\n",
    "from read_write_fused_vis import read_fused\n",
    "\n",
    "dense_ply = dense_dir / \"fused.ply\"\n",
    "dense_ply_vis = dense_dir / \"fused.ply.vis\"\n",
    "dense_ply_model = read_fused(dense_ply.as_posix(), dense_ply_vis.as_posix()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af19c1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"type(dense_ply_model): {type(dense_ply_model)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c5b801",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dense_ply_model[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c99e068",
   "metadata": {},
   "outputs": [],
   "source": [
    "mx_idx = -1\n",
    "for pt3d in tqdm(dense_ply_model):\n",
    "    idx_list = pt3d.visible_image_idxs\n",
    "    #print(f\"type(idx_list): {type(idx_list)}\")\n",
    "    mx_idx_in_list = max(idx_list)\n",
    "    mx_idx = max(mx_idx, mx_idx_in_list)\n",
    "    #print(f\"mx_idx_in_list: {mx_idx_in_list}\")\n",
    "print(f\"mx_idx: {mx_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbd440c-43d6-4abc-8c03-e2e783424884",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "c_1r = np.array([[1,0,0,0], \n",
    "                [0,1,0,1], \n",
    "                [0,0,1,2],\n",
    "                [0, 0, 0, 1]])\n",
    "c_2r = np.array([[1,0,0,3], \n",
    "                [0,1,0,4], \n",
    "                [0,0,1,5],\n",
    "                [0,0,0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f944d644-1a5a-4b43-b43b-e77715227409",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_1w = np.array([[1,0,0,0], \n",
    "                [0,1,0,0], \n",
    "                [0,0,1,0],\n",
    "                [0,0,0,1]])\n",
    "c_2w = np.array([[1,0,0,3], \n",
    "                [0,1,0,3], \n",
    "                [0,0,1,3],\n",
    "                [0,0,0,1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7dad80-548a-4f87-9a67-c753a9b12a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_rw = np.dot(np.linalg.inv(c_1r), c_1w)\n",
    "print(c_rw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae81f3b-8a76-48ec-9c44-3a528529426b",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_rw = np.dot(np.linalg.inv(c_2r), c_2w)\n",
    "print(c_rw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe4a6e2",
   "metadata": {},
   "source": [
    "### Analysing Dense PointCloud PLY files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6148c926",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dense_ply_model[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cf0352",
   "metadata": {},
   "source": [
    "### 3D to 2D mapping Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fc1928",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "fx = 1093.2768\n",
    "fy = 1093.2768\n",
    "cx = 964.989\n",
    "cy = 569.276\n",
    "A = np.array([[fx,0 , cx], [0, fy, cy], [0 , 0, 1]]).astype(np.float64)\n",
    "\n",
    "def get_camera_matrix(fx, fy, cx, cy):\n",
    "    return np.array([[fx,0 , cx], [0, fy, cy], [0 , 0, 1]]).astype(np.float64)\n",
    "\n",
    "'''\n",
    "A => Camera Matrix => 3 * 3\n",
    "R => Rotation Matrix => 3 * 3\n",
    "t => Translation Vector => 3 * 1\n",
    "P => Projection Matrix => 3 * 4\n",
    "'''\n",
    "def getP(A, R, t):\n",
    "    assert A.shape == (3,3)\n",
    "    assert R.shape == (3, 3)\n",
    "    assert t.shape == (3,1)\n",
    "    R_t = np.concatenate((R,t), axis = 1)\n",
    "    \n",
    "    #print(f\"A.shape: {A.shape}\")\n",
    "    #print(f\"R_t.shape: {R_t.shape}\")\n",
    "    #print(f\"t.shape: {t.shape}\")\n",
    "    P = np.dot(A ,R_t)\n",
    "    return P\n",
    "'''\n",
    "coords => 3 * 1 => (x, y, 1)\n",
    "'''\n",
    "def mask_value_at(img, coords):\n",
    "    mask_dir = images / \"segmentations\"\n",
    "    segmentation_masks = []\n",
    "    name = img.split('/')[-1] + \".png\"\n",
    "    mask_name = mask_dir.joinpath(name)\n",
    "    mask_img = cv2.imread(mask_name.as_posix(), cv2.IMREAD_GRAYSCALE)\n",
    "    coords = list(coords[:, 0])\n",
    "    return mask_img[int(coords[0]), int(coords[1])]\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b52ed1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "first5pairs = {k: sparse_img_dict[k] for k in list(sparse_img_dict)[:2]}\n",
    "print(f\"type(sparse_img_dict): {type(sparse_img_dict)}\")\n",
    "print(f\"type(first5pairs): {type(first5pairs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9669e2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(sparse_img_dict.items())[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3423243",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(sparse_img_dict.keys())[29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491ac8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sparse_keys[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2c0682",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/home/skumar/colmap/scripts/python\")\n",
    "from read_write_model import qvec2rotmat\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import numpy as np\n",
    "from progress.bar import Bar\n",
    "from read_write_model import read_images_binary\n",
    "#print(f\"sample_image: {images_bin[1]}\")\n",
    "\n",
    "no_mask_list = []\n",
    "mask_dict = {}\n",
    "mask_mapping_dict = {}\n",
    "\n",
    "#images_bin = read_images_binary(dense_images)\n",
    "dense_img_dict = read_images_binary(dense_images)\n",
    "sparse_img_dict = read_images_binary(sparse_images)\n",
    "\n",
    "#sparse_img_dict_list = list(sparse_img_dict)\n",
    "\n",
    "sparse_keys = list(sparse_img_dict.keys())\n",
    "\n",
    "print(f\"sparse_keys: {sparse_keys}\")\n",
    "\n",
    "for point3d in tqdm(dense_ply_model): \n",
    "    #print(f\"point3d.position: {type(point3d.position)} position[0]: {type(point3d.position[0])}\")\n",
    "    mask_found = False\n",
    "    mask_list = []\n",
    "    X = np.append(point3d.position, 1).reshape(4,-1)\n",
    "    #print(f\"X: {X} X.shape: {X.shape} type(X): {type(X)}\")\n",
    "    image_ids = point3d.visible_image_idxs\n",
    "    #print(f\"image_ids: {image_ids}\")\n",
    "    for image_id in image_ids: \n",
    "        #curr_img = sparse_img_dict[sparse_keys[image_id]]\n",
    "        curr_img = sparse_img_dict[image_id + 1]\n",
    "        R = qvec2rotmat(curr_img.qvec)\n",
    "        t = curr_img.tvec.reshape(3,-1)\n",
    "        P = getP(A, R, t)\n",
    "        x = np.dot(P , X) #project X onto image\n",
    "        x = x / x[2,0]\n",
    "        if x[0,0] < 1080 and x[0,0] > 0 and x[1,0] < 1920 and x[1,0] > 0:\n",
    "            curr_img_mask = mask_value_at(curr_img.name, x)\n",
    "            mask_found = True\n",
    "            key = (point3d.position[0], point3d.position[1], point3d.position[2])\n",
    "            #print(f\"key: {key} type(key): {type(key)}\")\n",
    "            mask_dict[key] = curr_img_mask\n",
    "            if curr_img_mask not in mask_mapping_dict: \n",
    "                mask_mapping_dict[curr_img_mask] = []\n",
    "            mask_mapping_dict[curr_img_mask].append(key)\n",
    "            #print(f\"curr_img_mask: {curr_img_mask}\")\n",
    "            break;\n",
    "        else:\n",
    "            pass\n",
    "    if not mask_found:\n",
    "        #print(f\"Could not find a mask for point : {point3d.position}\")\n",
    "        no_mask_list.append(point3d.position)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab018147",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"len(no_mask_list): {len(no_mask_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9ced84",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"len(no_mask_list): {len(no_mask_list)}  {len(no_mask_list)/ len(dense_ply_model) * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98adf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_mask_dict = {0: 'rgb(0,0,0)',\n",
    "                   1: 'rgb(246,4,228)',\n",
    "                   2: 'rgb(173, 94, 48)',\n",
    "                   3: 'rgb(68, 171, 117)',\n",
    "                   4: 'rgb(162, 122, 174)',\n",
    "                   5: 'rgb(121, 119, 148)',\n",
    "                   6: 'rgb(253, 75, 40)',\n",
    "                   7: 'rgb(170,60,100)',\n",
    "                   9: 'rgb(170,100,60)'    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e357f792",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_dict_list = list(mask_dict.keys())\n",
    "#print(mask_dict_list)\n",
    "pts3D_list = []\n",
    "for pts in mask_dict_list:\n",
    "    #print(f\"pts: {pts} type(pts): {type(pts)} type(pts[0]): {type(pts[0])}\")\n",
    "    pts3D_list.append(np.asarray(pts))\n",
    "#print(pts3D_list)\n",
    "pts3D_list = np.asarray(pts3D_list)\n",
    "#print(pts3D_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccda285",
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_points = no_mask_list\n",
    "invalid_points = np.asarray(invalid_points)\n",
    "fig3d = init_figure()\n",
    "plot_points(fig3d, invalid_points)\n",
    "fig3d.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37077f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig3d = init_figure()\n",
    "\n",
    "vine_stem_pts = None\n",
    "\n",
    "for key in mask_mapping_dict.keys():\n",
    "    '''if(len(mask_mapping_dict[key]) == 0):\n",
    "        print(\"0 value\")\n",
    "        continue\n",
    "    '''\n",
    "    if key != 4:\n",
    "        continue\n",
    "    print(f\"key: {key} color: {color_mask_dict[key]} len(mask_mapping_dict[key] : {len(mask_mapping_dict[key])}\")\n",
    "    pts_list = mask_mapping_dict[key]\n",
    "    pts = []\n",
    "    for pt in pts_list: \n",
    "        pts.append(np.asarray(pt))\n",
    "    pts = np.asarray(pts)\n",
    "    print(f\"type(pts) : {type(pts)} pts.shape: {pts.shape}\")\n",
    "    vine_stem_pts = pts \n",
    "    #print(f\"key: {key} pts.shape: {pts.shape} type(pts): {type(pts)} type(pts[0,0]): {type(pts[0,0])}\")\n",
    "    #plot_points(fig3d, pts, color_mask_dict[key], name=str(key))\n",
    "args = dict(max_reproj_error=3.0, min_track_length=2, cs=1.2)\n",
    "plot_reconstruction(fig3d, dense_colmap, color='rgba(255, 255, 0, 0.5)', name=\"dense_colmap\", **args)\n",
    "#plot_points(fig3d, invalid_points, color='rgba(255,0,0,0.5)', name=\"invalid_points\")\n",
    "\n",
    "fig3d.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae02bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"type(vine_stem_pts): {type(vine_stem_pts)} vine_stem_pts.shape: {vine_stem_pts.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92995719",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xyz = np.random.rand(100, 3)\n",
    "\n",
    "def write_as_ply(arr): \n",
    "    import open3d as o3d\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(arr)\n",
    "    #o3d.io.write_point_cloud(\"./data.ply\", pcd)\n",
    "    o3d.visualization.draw_geometries([pcd])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff438d5-dfc8-41ac-a862-148664b8e42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance(p1:np.array, p2:np.array):\n",
    "    return np.linalg.norm(p1-p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebfb643",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = np.array([-0.79,15.4116])\n",
    "p2 = np.array([-3.27,15.89])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6922b5a-2190-4cce-bd74-6b076cc0bd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dis = get_distance(p1,p2)\n",
    "print(f\"dis: {dis}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ac5f07",
   "metadata": {},
   "source": [
    "### Plotting Segemented Pointcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ed83fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig3d = init_figure()\n",
    "plot_points(fig3d, pts3D_list, name =\"k1\")\n",
    "plot_points(fig3d, pts3D_list, name =\"k2\")\n",
    "fig3d.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23e9def",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_map = pycolmap.Reconstruction()\n",
    "test_map.read_binary(\"/home/skumar/colmap_cli_output\")\n",
    "plot_reconstruction(test_map?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b51fd20",
   "metadata": {},
   "source": [
    "### Baseline check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663f2206",
   "metadata": {},
   "outputs": [],
   "source": [
    "from read_write_model import read_images_binary\n",
    "image_dict = read_images_binary(dense_images)\n",
    "print(image_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f975186d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cam_extrinsics(img):\n",
    "    from read_write_model import qvec2rotmat\n",
    "    R = qvec2rotmat(img.qvec)\n",
    "    t = img.tvec.reshape(3,-1)\n",
    "    R_t = np.concatenate((R,t), axis = 1)\n",
    "    R_t = np.vstack([np.array([0,0,0,1]), R_t])\n",
    "    return R_t    #  4 * 4 matrix\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d23781",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "e_lw => left camera pose in world frame (4 * 4)\n",
    "e_rw => right camera pose in world frame (4 * 4)\n",
    "'''\n",
    "def calculate_relative_pose(e_lw, e_rw): \n",
    "    from scipy.spatial.transform import Rotation\n",
    "    e_rl = e_rw * np.linalg.inv(e_lw) #right camera in the frame of the left camera\n",
    "    R = e_rl[:3,:3] #extracting the rotation matrix\n",
    "    dx = e_rl[0,3]\n",
    "    dy = e_rl[1,3]\n",
    "    dz = e_rl[2,3]\n",
    "    dquat = Rotation.from_matrix(R).as_quat()\n",
    "    #rel_pose =  [dx, dy] + dquat\n",
    "    rel_pose = [dx,dy,dz]\n",
    "    for q in dquat: \n",
    "        rel_pose.append(q)\n",
    "    return rel_pose\n",
    "    #return [dx,dy]\n",
    "    #print(f\"dx: {dx} dy: {dy} dquat: {dquat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1fcd10-f366-4205-99f7-a5a64246812d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''pose of cam1 in the frame of rig'''\n",
    "e_1r = np.array([[1, 0, 0, 0.06], \n",
    "                [0, 1, 0, 0],\n",
    "                [0, 0, 1, 0], \n",
    "                [0, 0, 0, 1]])\n",
    "\n",
    "''' pose of rig in the frame of cam1'''\n",
    "e_r1 = np.linalg.inv(e_1r)\n",
    "\n",
    "print(e_r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0cf86b-6cd5-40ef-ab07-404d700ee34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(e_r1 ,e_1r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cd9eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_poses = []\n",
    "for idx in range(0, num_images - 1,2): \n",
    "    '''\n",
    "    if idx > 1:\n",
    "        break\n",
    "    '''\n",
    "    left_img = sparse_img_dict[idx + 1]\n",
    "    right_img = sparse_img_dict[idx + 2]\n",
    "    e_lw = cam_extrinsics(left_img)  #left camera pose w.r.t. world\n",
    "    e_rw = cam_extrinsics(right_img) #right camera pose w.r.t world\n",
    "    rel_pose = calculate_relative_pose(e_lw, e_rw)\n",
    "    rel_poses.append(rel_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b2a6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (rel_poses[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2507114d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "df = pd.DataFrame(rel_poses, columns=['dx', 'dy', 'dz', 'qx' , 'qy', 'qz' , 'qw'])\n",
    "df.style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4799f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(24)\n",
    "df = pd.DataFrame({'A': np.linspace(1, 10, 10)})\n",
    "df = pd.concat([df, pd.DataFrame(np.random.randn(10, 4), columns=list('BCDE'))],\n",
    "               axis=1)\n",
    "df.iloc[0, 2] = np.nan\n",
    "df.style"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd57fbbf",
   "metadata": {},
   "source": [
    "# Localization\n",
    "Now that we have a 3D map of the scene, we can localize any image. To demonstrate this, we download [a night-time image from Wikimedia](https://commons.wikimedia.org/wiki/File:Paris_-_Basilique_du_Sacr%C3%A9_Coeur,_Montmartre_-_panoramio.jpg)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad9b558",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://upload.wikimedia.org/wikipedia/commons/5/53/Paris_-_Basilique_du_Sacr%C3%A9_Coeur%2C_Montmartre_-_panoramio.jpg\"\n",
    "# try other queries by uncommenting their url\n",
    "# url = \"https://upload.wikimedia.org/wikipedia/commons/8/8e/Sacr%C3%A9_C%C5%93ur_at_night%21_%285865355326%29.jpg\"\n",
    "# url = \"https://upload.wikimedia.org/wikipedia/commons/c/c0/La_basilique_du_Sacr%C3%A9-Coeur_au_cr%C3%A9puscule_%28Paris%29_%284147593805%29.jpg\"\n",
    "query = 'query/night.jpg'\n",
    "!mkdir -p $images/query && wget $url -O $images/$query -q\n",
    "plot_images([read_image(images / query)], dpi=75)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854edc74",
   "metadata": {},
   "source": [
    "Again, we extract features for the query and match them exhaustively with all mapping images that were successfully reconstructed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dc9cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "references_registered = [refined.images[i].name for i in refined.reg_image_ids()]\n",
    "extract_features.main(feature_conf, images, image_list=[query], feature_path=features, overwrite=True)\n",
    "pairs_from_exhaustive.main(loc_pairs, image_list=[query], ref_list=references_registered)\n",
    "match_features.main(matcher_conf, loc_pairs, features=features, matches=matches, overwrite=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa75646",
   "metadata": {},
   "source": [
    "We read the EXIF data of the query to infer a rough initial estimate of camera parameters like the focal length. Then we estimate the absolute camera pose using PnP+RANSAC and refine the camera parameters. Under the hood, the `QueryLocalizer` takes care of extracting dense features for the query and runs the keypoint and pose adjustments, QKA and QBA. The refinement refines the camera parameters in-place so we can inspect them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a68b8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycolmap\n",
    "from pixsfm.localize import QueryLocalizer, pose_from_cluster\n",
    "\n",
    "camera = pycolmap.infer_camera_from_image(images / query)\n",
    "ref_ids = [refined.find_image_with_name(r).image_id for r in references_registered]\n",
    "conf = {\n",
    "    \"dense_features\": sfm.conf.dense_features,  # same features as the SfM refinement\n",
    "    \"PnP\": {  # initial pose estimation with PnP+RANSAC\n",
    "        'estimation': {'ransac': {'max_error': 12.0}},\n",
    "        'refinement': {'refine_focal_length': True, 'refine_extra_params': True},\n",
    "    },\n",
    "    \"QBA\": {  # query pose refinement\n",
    "        \"optimizer:\": {'refine_focal_length': True, 'refine_extra_params': True},\n",
    "    }\n",
    "}\n",
    "dense_features = sfm_outputs[\"feature_manager\"]\n",
    "localizer = QueryLocalizer(refined, conf, dense_features=dense_features)\n",
    "ret, log = pose_from_cluster(localizer, query, camera, ref_ids, features, matches, image_path=images/query)\n",
    "\n",
    "print(f'found {sum(ret[\"inliers\"])}/{len(ret[\"inliers\"])} inlier correspondences.')\n",
    "visualization.visualize_loc_from_log(images, query, log, refined, top_k_db=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612f23aa",
   "metadata": {},
   "source": [
    "We visualize the correspondences between the query images a few mapping images. We can also visualize the estimated camera pose in the 3D map, shown here in blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558eb121",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose = pycolmap.Image(tvec=ret['tvec'], qvec=ret['qvec'])\n",
    "plot_camera_colmap(fig3d, pose, camera, color='rgba(128,128,255,0.5)', name=query, legendgroup=\"refined\")\n",
    "fig3d.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
